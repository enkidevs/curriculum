---
author: Stefan-Stojanovic
type: normal
category: discussion
 

---

# ChatGPT Limitations

---

## Content

---

Keep in mind that **ChatGPT** can sometimes make mistakes or give strange responses depending on the prompts you give it.

Sometimes, ChatGPT hallucinates[1] and confidently gives a wrong response. It might be very smart and advanced, but it is a fancy auto-complete[2] after all.

Some limitations to keep in mind:

### Arithmetic and puzzles
---

It may sometimes generate inaccurate or inappropriate responses. It struggles with arithmetic and puzzles in particular.

Here's an example of a hallucination:

![list-of-words-with-select-letters](https://img.enkipro.com/40d030c590c998b67b32b4312ba0c35e.png)

### No Emotional Intelligence
---

This means the AI may not always be able to recognize or respond appropriately to emotions expressed in text input.

### Contextual Understanding
---

ChatGPT may not always understand the context or underlying meaning of a question properly:

![quantum-computing](https://img.enkipro.com/451536ac3abadb294e6582641bc427e4.png)

### Knowledge Limitations
---

ChatGPT has some limitations with up-to-date information, and rapidly evolving topics in particular:

![covid-19](https://img.enkipro.com/7a98fbe1ba4646751e01ccce7bdd0d08.png)


---
## Footnotes

[1: AI Hallucination]

AI hallucinations happen when artificial intelligence systems generate outputs that lack factual basis or are fictional due to their inability to truly understand the input. These responses should be approached with scepticism as they do not provide accurate information.

[2: Fancy Autocomplete]

ChatGPT is a highly advanced language model that, in essence, functions like an intelligent auto-complete. It leverages its extensive training data and powerful transformer architecture to generate context-aware, coherent, and human-like responses, going far beyond the capabilities of traditional auto-complete tools.