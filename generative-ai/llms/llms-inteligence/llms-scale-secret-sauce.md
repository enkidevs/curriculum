---
author: nemanjaenki
type: normal
category: must-know
---

# ğŸ“ˆ Scale is the Secret Sauce

---

## Content

ChatGPT's power comes from scale â€” the massive size of its training data and model architecture.

GPT-3 was trained on 500 billion words, while a human child might hear only 100 million words by age 10.

GPT-4 is trained on 100 trillion tokens, which is 1000x more data than GPT-3.

> ğŸ’¡ LLM + more data = improved performance.
