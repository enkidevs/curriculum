---
author: nemanjaenki
type: normal
category: must-know
practiceQuestion:
  formats:
    - fill-in-the-gap
  context: standalone
revisionQuestion:
  formats:
    - fill-in-the-gap
  context: standalone
---

# ðŸ”„ Scaling with Balance

---

## Content

Scaling only works when model size, data size, and compute grow together.

Doubling the size of a model without increasing data or compute doesnâ€™t yield proportional gains.

GPT-3's success relied on balancing 175 billion parameters with massive training data and compute power.

> ðŸ’¡ bigger LLM + more data + more compute = best performance.

---

## Practice

Mark the required aspects that are needed for LLMs to perform better with scaling.

```
A: bigger LLM
B: more data
C: more compute
```

???

- A, B, C
- A, B
- A, C
- B, C

---

## Revision

Mark the required aspects that are needed for LLMs to perform better with scaling.

```
A: bigger LLM
B: more data
C: more compute
```

???

- A, B, C
- A, B
- A, C
- B, C
