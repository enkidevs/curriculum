---
author: nemanjaenki
type: normal
category: must-know
links:
  - >-
    [Interpretability of GPT-2](https://arxiv.org/abs/2211.00593)
---

# ðŸ§© GPT-2 Close-Up

---

## Content

Unraveling why GPT-2 predicted `"Mary"` took researchers months and a 25-page
paper.

Despite their efforts, questions remain:

- How did GPT-2 decide the next word should be a name?
- Why didn't it predict something like `"the cashier"`?

> ðŸ’« GPT-2's prediction process was complex, involving specialized attention
> heads and layers of reasoning.
