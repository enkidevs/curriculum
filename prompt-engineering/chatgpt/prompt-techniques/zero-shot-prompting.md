---
author: Stefan-Stojanovic
type: normal
category: must-know
 

---

# Zero-Shot Prompting

---

## Content

---

**Zero-shot** prompting is a technique in which a language model is able to generate language output for tasks it has not been explicitly trained on, without any additional training or fine-tuning. 

**Zero-shot** prompting is possible because language models are trained on a large corpus of text, and they can learn to understand the relationships between different concepts and topics.

The key benefit of **zero-shot** prompting is that it allows for generating outputs for new tasks without requiring any additional training data or fine-tuning.

It can be used in various applications, such as language translation:

![translation-prompt](https://img.enkipro.com/23dc4d5c1a4340910aff4cadbe1e5447.png)

summarization:

![summarization-prompt](https://img.enkipro.com/49d49240a1e8bce77dabb11445ab7e35.png)

and dialogue generation:

![dialogue-prompt](https://img.enkipro.com/e658eb1c427d2026a46522f31f53cb34.png)